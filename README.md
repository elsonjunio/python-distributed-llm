# python-distributed-llm

A ideia de criar um sistema distribuÃ­do para execuÃ§Ã£o de modelos LLM (como LLaMA ou Phi-3) dividido entre mÃ¡quinas com poucos recursos, com um gerenciador coordenando os workers, tem vÃ¡rias vantagens importantes, tanto tÃ©cnicas quanto estratÃ©gicas.

âœ… Vantagens principais

ğŸ§© 1. Aproveitamento de hardware modesto

    MÃ¡quinas fracas isoladas nÃ£o conseguem rodar o modelo inteiro, mas cooperando podem executar partes.

    Reduz a dependÃªncia de uma Ãºnica mÃ¡quina potente (com muita RAM e CPU/GPU).

ğŸ’° 2. Custo reduzido

    Evita comprar hardware caro.

    VocÃª pode usar mini-PCs, Raspberry Pi, Orange Pi, VPSs baratos, PCs antigos, etc.

    Usa o que jÃ¡ tem â€” Ã³tima ideia para home labs ou ambientes educacionais.

ğŸ§  3. Entendimento profundo de como um LLM funciona

    Obriga a entender o pipeline interno de inferÃªncia, camadas, tensores, e otimizaÃ§Ãµes.

    Excelente aprendizado para quem quer trabalhar com sistemas distribuÃ­dos e LLMs.

ğŸš€ 4. Escalabilidade horizontal

    Quando quiser mais performance, adicione mais nÃ³s ao cluster.

    Pode fazer sharding mais fino (mais camadas por nÃ³) ou balancear carga por token, etc.

ğŸ”„ 5. Flexibilidade arquitetural

    Pode:

        Substituir partes do modelo,

        Trocar o backend (PyTorch, GGUF, etc.),

        Integrar cache, prefetch, compressÃ£o de tensores, etc.

ğŸ§ª 6. Testbed para inovaÃ§Ã£o

    Este MVP vira uma base para:

        Explorar novos protocolos (ZeroMQ, gRPC),

        Testar compressÃ£o de dados em tempo real,

        Rodar modelos heterogÃªneos (parte no CPU, parte em GPU),

        Usar quantizaÃ§Ã£o sob demanda (ex: ativaÃ§Ã£o em int8, atenÃ§Ã£o em fp32).

ğŸ§° 7. Controle total

    Diferente de frameworks fechados (como DeepSpeed, vLLM), vocÃª controla cada etapa.

    Pode customizar tudo: agendamento, balanceamento, cache de atenÃ§Ã£o, etc.

ğŸ“¡ 8. IndependÃªncia de cloud / open-source por completo

    Pode funcionar offline ou em redes internas (LAN).

    Ideal para aplicaÃ§Ãµes sensÃ­veis (privacidade, edge computing, defesa, indÃºstria).

ğŸ› ï¸ Use cases viÃ¡veis

    Chatbots embarcados, com o modelo rodando parcialmente em cada nÃ³.

    Clusters de edge computing, onde cada nÃ³ Ã© simples (IoT, SBCs).

    Pesquisas sobre inferÃªncia distribuÃ­da.

    EducaÃ§Ã£o em sistemas paralelos e IA.


Teste de execuÃ§Ã£o de inferÃªncia de modo distribuido

```bash
cd worker1 && uvicorn main:app --host 0.0.0.0 --port 8001
cd worker2 && uvicorn main:app --host 0.0.0.0 --port 8002
cd master && python main.py
```

criado dia 2025-05-05

##
ImplementaÃ§Ã£o com safetensors exige a criaÃ§Ã£o de todas as etapas do Transformer (attention, MLP, residuals, etc) (Pausado para estudos).